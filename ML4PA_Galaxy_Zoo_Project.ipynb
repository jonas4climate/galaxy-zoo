{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCcKICIGV6Bw"
      },
      "source": [
        "# Galaxy Imagery Classification\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Understanding the origins and evolution of galaxies is a fundamental aspect of astronomy. As galaxies come in various shapes, sizes, and may contain differing features, classifying them based on their morphology is an important task for astronomical research in this domain. To utilize galaxy imagery data effectively, such classification must be reliable and scalable. The [Galaxy Zoo](https://zoo4.galaxyzoo.org/) project, a pioneering citizen science initiative, has made significant strides in this domain by allowing volunteers to visually classify galaxy images from the [Sloan Digital Sky Survey](http://www.sdss.org/). However, with the rise of increasingly sophisticated and larger astronomical datasets, particularly of image data, there is a clear need for automation of this classification process.\n",
        "\n",
        "The Galaxy Zoo Challenge as hosted on Kaggle, aims to address this need by opening a competition around suitable machine learning techniques to classify galaxies for a large dataset of images. Participants are tasked with developing algorithms that can replicate the probability distributions of galaxy classifications derived from the data obtained by human volunteers.\n",
        "\n",
        "In this report, we explore different artificial neural network (ANN) architectures, predominately convolutional neural networks (CNN) and the application of transfer learning to the Galaxy Zoo dataset. CNNs have revolutionized image processing tasks due to their ability to automatically learn hierarchical features from raw image data and with the rise of deep learning, large models enable classification of large and complex patterns in data. Transfer learning, a technique that utilizes pre-trained models on new, but related tasks, offers a promising approach to improving classification performance, especially when dealing with limited labeled data.\n",
        "\n",
        "The objective of our report is to evaluate the performance of various ANN architectures and assess the potential ways to use transfer learning on the accuracy of galaxy classification. By doing so, we aim to explore potential avenues for future research of robust classification systems on astronomical imagery data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9FEc-GHHrHA"
      },
      "source": [
        "## Data Description\n",
        "\n",
        "The data utilized in this study is derived from the Galaxy Zoo challenge which can be found using the following [link](https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge) directing to Kaggle. This dataset includes 61.579 training and 79.976 test images of galaxies, the training data accompanied with a csv file containing labels for the target vector of 37 values representing the possible answers to 11 feature questions from the survey. As the values are probability distributions of various morphological galaxy features, the probability for each class would sum to 1, however, as some questions are conditional on the answers of previous questions, this is not the case. The final probabilistic values are based on a detailed decision tree design as can be seen below and are post-processed and weighted averages of the classifications made by the citizen scientists.\n",
        "\n",
        "![Decision Tree image](media/decision_tree.png)\n",
        "\n",
        "The dataset is divided into two datasets, one for training and one for testing on Kaggle. The training dataset consists of JPG images of galaxies with the center of each galaxy positioned in the center of each image. The test dataset includes similar images of galaxies, which are used to evaluate the performance of the models. Predictions for the test dataset should be formatted according to Kaggle's submission requirements, listing the GalaxyID and the predicted probabilities for each class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoOm5nOIWlfg"
      },
      "source": [
        "Fill in your Kaggle API credentials below. Do note to keep these private if you intend on publishing a derived version of this notebook!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0zo9x4BVyrB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'joneron'\n",
        "os.environ['KAGGLE_KEY'] = 'd495db6490b0e9b3ac98e008034829c9'\n",
        "import kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG4dJBskX8ID"
      },
      "source": [
        "Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZbV4pivV3Uj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import densenet121, resnet18\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_IZ69QxY5za"
      },
      "source": [
        "Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8Ory5GvXYSL"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "DATA_PATH = 'data'\n",
        "MEDIA_PATH = 'media'\n",
        "MODEL_PATH = 'models'\n",
        "[os.makedirs(path, exist_ok=True) for path in [MEDIA_PATH, MODEL_PATH]]\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8TfzrRAY8vd"
      },
      "source": [
        "Check which accelerator is available. Change runtime within Google Colab or adjust based on your available hardware."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7JO3djsY7UB",
        "outputId": "c3fdfe8d-5b05-4cf3-e3c7-6248a53ff6b1"
      },
      "outputs": [],
      "source": [
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(f'Training on {device}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65LBs1mjHrHD"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "The data from kaggle was downloaded and extracted from its zip archives to obtain images and CSV label file. Next, the file links to assign labels to the corresponding dtraining data in the CSV label file were parsed and updated to correspond to our environment setup. To ensure robust model training and no additional image order biases, the data was shuffled and split into a training and validation sets using a 80/20 ratio. This step helps to prevent overfitting and provides a means to evaluate model performance on a separate validation set. A custom dataset class was defined to facilitate efficient loading of images and labels during training. Various image preprocessing transformations were considered, such as converting images to grayscale, cropping, resizing, and normalizing pixel values. Example transformations were visualized to ensure the correctness of the preprocessing steps and to select the most effective transformation pipeline for the training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eknmlf5RZOIL"
      },
      "source": [
        "Downloading and unpacking dataset files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzpCSswnY-WH",
        "outputId": "bde6ea54-8a3c-4620-8a89-b61d44fd3964"
      },
      "outputs": [],
      "source": [
        "challenge_name = 'galaxy-zoo-the-galaxy-challenge'\n",
        "\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    os.makedirs(DATA_PATH)\n",
        "\n",
        "    kaggle.api.authenticate()\n",
        "    kaggle.api.competition_download_files(challenge_name, path=DATA_PATH)\n",
        "\n",
        "    # Extract competition zip file\n",
        "    with ZipFile(f'{DATA_PATH}/{challenge_name}.zip', 'r') as zipf:\n",
        "        zipf.extractall(DATA_PATH)\n",
        "\n",
        "    # Extract contained train, test zip files within\n",
        "    for file in os.listdir(DATA_PATH):\n",
        "        if file.endswith('.zip'):\n",
        "            with ZipFile(f'{DATA_PATH}/{file}', 'r') as zipf:\n",
        "                zipf.extractall(DATA_PATH)\n",
        "\n",
        "    # Only keep data and clear zips\n",
        "    for file in os.listdir(DATA_PATH):\n",
        "        if file.endswith('.zip'):\n",
        "            os.remove(f'{DATA_PATH}/{file}')\n",
        "    print('Setup complete.')\n",
        "else:\n",
        "    print('Setup skipped, files detected.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgfklVgKZnxX"
      },
      "source": [
        "Load training targets and reformat URL strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "KNdtL3ioZRfE",
        "outputId": "6a7c8ed3-fddb-49f1-91bb-8a0b8843d51a"
      },
      "outputs": [],
      "source": [
        "# Parse and reformat\n",
        "train_img_dir = f'{DATA_PATH}/images_training_rev1/'\n",
        "train_full = pd.read_csv(f'{DATA_PATH}/training_solutions_rev1.csv')\n",
        "train_full['GalaxyID'] = train_full['GalaxyID'].astype(int).astype(str) + '.jpg'\n",
        "train_full['GalaxyID'] = train_full['GalaxyID'].str.zfill(8)\n",
        "train_full['GalaxyID'] = train_img_dir + train_full['GalaxyID']\n",
        "\n",
        "# Shuffle data and split into training and validation dataset based on a 80/20 ratio split.\n",
        "train_full = train_full.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
        "train, validation = train_test_split(train_full, test_size=0.2, random_state=SEED)\n",
        "\n",
        "# Visually inspect data targets\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5kI3uUyae9H"
      },
      "source": [
        "Dataset class definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLM4upUEaXkC"
      },
      "outputs": [],
      "source": [
        "classes = ['Class1.1', 'Class1.2', 'Class1.3', 'Class2.1', 'Class2.2', 'Class3.1', 'Class3.2', 'Class4.1', 'Class4.2', 'Class5.1', 'Class5.2', 'Class5.3', 'Class5.4', 'Class6.1', 'Class6.2', 'Class7.1', 'Class7.2', 'Class7.3', 'Class8.1', 'Class8.2', 'Class8.3', 'Class8.4', 'Class8.5', 'Class8.6', 'Class8.7', 'Class9.1', 'Class9.2', 'Class9.3', 'Class10.1', 'Class10.2', 'Class10.3', 'Class11.1', 'Class11.2', 'Class11.3', 'Class11.4', 'Class11.5', 'Class11.6']\n",
        "n_sub_classes = [3, 2, 2, 2, 4, 2, 3, 7, 3, 3, 6]\n",
        "n_main_classes = 11\n",
        "n_classes = len(classes)\n",
        "\n",
        "class GalaxyDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.df.iloc[idx, 0]\n",
        "        img = plt.imread(img_name)\n",
        "        label = self.df.iloc[idx, 1:].values.astype(float)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpvQwO4kaCKF"
      },
      "source": [
        "Preprocessing configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1HGnNjpMaIkD",
        "outputId": "b2c4bb80-900d-4d21-ac1f-1cba5462bd39"
      },
      "outputs": [],
      "source": [
        "def get_transform_config(grayscale=False, crop=None, resize=None):\n",
        "    \"\"\"\n",
        "    Returns a composition of transformations for preprocessing images\n",
        "    \"\"\"\n",
        "    transform = []\n",
        "    transform.append(transforms.ToPILImage())\n",
        "    if grayscale:\n",
        "        transform.append(transforms.Grayscale(num_output_channels=1))\n",
        "    if crop:\n",
        "        transform.append(transforms.CenterCrop(crop))\n",
        "    if resize:\n",
        "        transform.append(transforms.Resize(resize))\n",
        "    transform.append(transforms.ToTensor())\n",
        "    return transforms.Compose(transform)\n",
        "\n",
        "def view_example_transforms(transform_configs, config_names, n_examples=5):\n",
        "    \"\"\"\n",
        "    Displays original and transformed images\n",
        "    \"\"\"\n",
        "    n_configs = len(transform_configs)\n",
        "    fig, axes = plt.subplots(n_configs, n_examples, figsize=(3*n_examples, 3.5*n_configs))\n",
        "\n",
        "    config_names = list(config_names)  # Convert dict_keys to list\n",
        "\n",
        "    for i, transform in enumerate(transform_configs):\n",
        "        dataset = GalaxyDataset(train, transform)\n",
        "\n",
        "        for j in range(n_examples):\n",
        "            img, label = dataset[j]\n",
        "            if img.shape[0] == 1:\n",
        "                img = img.squeeze(0)\n",
        "                axes[i, j].imshow(img, cmap='gray')\n",
        "            else:\n",
        "                img = img.permute(1, 2, 0)\n",
        "                axes[i, j].imshow(img)\n",
        "            axes[i, j].axis('off')\n",
        "\n",
        "        axes[i, int(np.floor(n_examples/2))].set_title(config_names[i], fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "transform_configs = {\n",
        "    'Original': get_transform_config(),\n",
        "    'Grayscale': get_transform_config(grayscale=True),\n",
        "    'Grayscale + Crop 256': get_transform_config(grayscale=True, crop=256),\n",
        "    'Grayscale + Crop 256 + Resize 128': get_transform_config(grayscale=True, crop=256, resize=128),\n",
        "    'Grayscale + Crop 256 + Resize 64': get_transform_config(grayscale=True, crop=256, resize=64)\n",
        "}\n",
        "\n",
        "view_example_transforms(transform_configs.values(), transform_configs.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBUSsZArHrHD"
      },
      "source": [
        "## Methodology\n",
        "\n",
        "### Custom network architectures\n",
        "\n",
        "We designe two neural network architectures: a convolutional network (`ConvNet`) and a fully linear network (`LinNet`). The `ConvNet` consists of three convolutional layers followed by ReLU activation and max-pooling layers. It also includes fully connected layers to produce the final classification output. In contrast, `LinNet` is a simpler baseline model with fully connected layers but no convolutional layers, used to compare performance benefits.\n",
        "\n",
        "### Transfer Learning\n",
        "\n",
        "As an alternative approach, we utilize the `DenseNet121` and `ResNet18` architecture, pre-trained on the [ImageNet](https://image-net.org/) dataset, for transfer learning. By replacing and training the final classification layer on our galaxy dataset while freezing the initial layers, we attempt to leverage the pre-trained model feature extraction capabilities to ideally improve performance and reducing training time.\n",
        "\n",
        "### Training process\n",
        "\n",
        "The models were trained using the Root Mean Squared Error (RMSE) loss function as is employed by the challenge assessment. For optimization, the Adam optimizer is utilized as it is generally accepted as a well-performing optimizer. After setting up datasets for training and validation, we selected the best initial weights through multiple training trials and employ early stopping in the longer training procedure that follows to prevent overfitting.\n",
        "\n",
        "### Parameter selection\n",
        "\n",
        "Hyperparameters such as learning rate, batch size, and the number of epochs were chosen within commonly used ranges. The training and validation losses were plotted to monitor the learning process. A thorough analysis was not performed.\n",
        "\n",
        "### Metrics\n",
        "\n",
        "The accuracy of our model is determined using its likelihood to predict the most probable outcome of a class. This is a simplification as the accuracy ideally reflects the entire probability distribution as is expressed by RMSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cujp5k3YHrHD"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional network\n",
        "    \"\"\"\n",
        "    def __init__(self, dim=424, in_channels=3, intermed_size=300):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.dim = dim\n",
        "        self.conv1 = nn.Conv2d(in_channels, 10, kernel_size=4)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=4)\n",
        "        self.conv3 = nn.Conv2d(20, 40, kernel_size=4)\n",
        "\n",
        "        self.fc1 = nn.Linear(1000, intermed_size)\n",
        "        self.fc2_qs = nn.ModuleList([nn.Linear(intermed_size, n) for n in n_sub_classes])\n",
        "\n",
        "    def forward(self, x):\n",
        "        n_batch = x.size(0)\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv3(x), 2))\n",
        "        x = x.view(n_batch, -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = torch.cat([F.sigmoid(fc(x)) for fc in self.fc2_qs], dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class LinNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Fully linear network\n",
        "    \"\"\"\n",
        "    def __init__(self, dim=424, in_channels=3):\n",
        "        super(LinNet, self).__init__()\n",
        "        self.dim = dim\n",
        "        self.fc1 = nn.Linear(dim*dim*in_channels, 300)\n",
        "        self.fc2_qs = nn.ModuleList([nn.Linear(300, n) for n in n_sub_classes])\n",
        "\n",
        "    def forward(self, x):\n",
        "        n_batch = x.size(0)\n",
        "        x = x.view(n_batch, -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = torch.cat([F.sigmoid(fc(x)) for fc in self.fc2_qs], dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "def DenseNet121(n_classes):\n",
        "    model = densenet121(pretrained=True, memory_efficient=True) # Load pretrained model\n",
        "    model.classifier = nn.Linear(1024, n_classes)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.classifier.parameters():\n",
        "        param.requires_grad = True\n",
        "    return model\n",
        "\n",
        "\n",
        "def ResNet18(n_classes):\n",
        "    model = resnet18(pretrained=True) # Load pretrained model\n",
        "    model.fc = nn.Linear(512, n_classes)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.fc.parameters():\n",
        "        param.requires_grad = True\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKHQbqVlaUh1"
      },
      "source": [
        "Training and evaluation code for networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qpgz1te7aSRU"
      },
      "outputs": [],
      "source": [
        "def rmse_loss(y_pred, y_true):\n",
        "    return torch.sqrt(F.mse_loss(y_pred, y_true))\n",
        "\n",
        "def hierarchical_loss(outputs, targets, n_sub_classes=n_sub_classes):\n",
        "    \"\"\"\n",
        "    Custom loss function that respects the hierarchical structure of the decision tree.\n",
        "    \"\"\"\n",
        "    loss = 0\n",
        "    start = 0\n",
        "    for n in n_sub_classes:\n",
        "        end = start + n\n",
        "        loss += F.binary_cross_entropy(outputs[:, start:end], targets[:, start:end])\n",
        "        start = end\n",
        "    return loss\n",
        "\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader, n_epochs=10, show_avg_loss=100, exclude_init_val=False):\n",
        "    \"\"\"\n",
        "    Trains the model using the given criterion, optimizer and data loader for a given number of epochs or until converged\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    metrics = {\n",
        "        'train_loss_by_batch': [],\n",
        "        'val_loss_by_epoch': []\n",
        "    }\n",
        "\n",
        "    train_loss = metrics['train_loss_by_batch']\n",
        "    val_loss = metrics['val_loss_by_epoch']\n",
        "\n",
        "    pbar = tqdm(total=len(train_loader) * n_epochs, leave=False, desc='Loss: ')\n",
        "\n",
        "    if not exclude_init_val:\n",
        "        # Validate once for initial loss\n",
        "        mean_loss, _ = validate_model(model, criterion, val_loader)\n",
        "        val_loss.append(mean_loss)\n",
        "\n",
        "    for n in range(n_epochs):\n",
        "        # Train\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.float().to(device)\n",
        "            labels = labels.float().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss.append(loss.item())\n",
        "            pbar.update(1)\n",
        "            if i % show_avg_loss == show_avg_loss-1:\n",
        "                pbar.set_description(f'Loss: {sum(train_loss[-show_avg_loss:])/show_avg_loss:.4f}')\n",
        "\n",
        "        # Validate to test for over-fitting\n",
        "        mean_loss, _ = validate_model(model, criterion, val_loader)\n",
        "        val_loss.append(mean_loss)\n",
        "\n",
        "        if n > 2:\n",
        "            if val_loss[n-2] < val_loss[n-1] < val_loss[n]:\n",
        "                pbar.close()\n",
        "                # Loss increased twice in a row on validation set so we seem to have converged\n",
        "                break\n",
        "    pbar.close()\n",
        "    return model, metrics\n",
        "\n",
        "def reset_init_weights(model):\n",
        "    \"\"\"\n",
        "    Resets the initial weights of the model using Xavier initialization\n",
        "    \"\"\"\n",
        "    if isinstance(model, nn.Conv2d) or isinstance(model, nn.Linear):\n",
        "        nn.init.xavier_uniform_(model.weight)\n",
        "        model.bias.data.fill_(0.01)\n",
        "\n",
        "def select_best_initial_weights(model, criterion, lr, train_loader, val_loader, n_epochs=1, n_trials=10):\n",
        "    \"\"\"\n",
        "    Selects the best initial weights for the model by running multiple short training cycles and selecting the best performing model\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    best_loss = np.inf\n",
        "    best_weights = None\n",
        "    pbar = tqdm(range(n_trials), desc='Trial', leave=False)\n",
        "    for _ in pbar:\n",
        "        model.apply(reset_init_weights) # Reset initial random weights\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "        model, metrics = train_model(model, criterion, optimizer, train_loader, val_loader, n_epochs)\n",
        "        test_loss, test_accuracy = validate_model(model, criterion, val_loader)\n",
        "        cross_accuracy = torch.mean(test_accuracy)\n",
        "        pbar.set_description(f'Test accuracy: {cross_accuracy}')\n",
        "        if test_loss < best_loss:\n",
        "            best_loss = test_loss\n",
        "            best_weights = model.state_dict()\n",
        "            best_weights_metrics = metrics\n",
        "    return best_weights, best_weights_metrics\n",
        "\n",
        "def train_best_model(model, criterion, optimizer, lr, train_loader, val_loader, n_train_epochs, n_trial_epochs=1, n_trials=10, save_model=False, model_name=None):\n",
        "    \"\"\"\n",
        "    If in doubt, the most comprehensive training.\n",
        "    Trains the model by selecting the best initial weights and then performing training for given number of epochs.\n",
        "    \"\"\"\n",
        "    best_weights, metrics = select_best_initial_weights(model, criterion, lr, train_loader, val_loader, n_epochs=n_trial_epochs, n_trials=n_trials)\n",
        "    model.load_state_dict(best_weights)\n",
        "    model = model.to(device)\n",
        "    if n_trial_epochs < n_train_epochs:\n",
        "        model, further_metrics = train_model(model, criterion, optimizer, train_loader, val_loader, n_train_epochs-n_trial_epochs, exclude_init_val=True)\n",
        "        metrics = merge_metrics(metrics, further_metrics)\n",
        "    if save_model:\n",
        "        torch.save(model.state_dict(), f'{MODEL_PATH}/{model_name}.pt')\n",
        "    # Merge metrics\n",
        "    return model, metrics\n",
        "\n",
        "def validate_model(model, criterion, val_loader):\n",
        "    \"\"\"\n",
        "    Validates the model using the given criterion and data loader\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    multiclass_acc = torch.zeros((11))\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.float().to(device)\n",
        "            labels = labels.float().to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            multiclass_acc += get_accuracy(outputs, labels)\n",
        "\n",
        "    mean_loss = total_loss / len(val_loader)\n",
        "    mean_multiclass_acc = multiclass_acc / len(val_loader)\n",
        "    return mean_loss, mean_multiclass_acc\n",
        "\n",
        "def merge_metrics(metrics1, metrics2):\n",
        "    \"\"\"\n",
        "    Merges two metrics dictionaries\n",
        "    \"\"\"\n",
        "    merged = {}\n",
        "    for key in metrics1.keys():\n",
        "        if type(metrics1[key]) == list:\n",
        "            merged[key] = metrics1[key] + metrics2[key]\n",
        "        else:\n",
        "            raise ValueError('Only lists are supported for merging')\n",
        "    return merged\n",
        "\n",
        "def get_accuracy(outputs, labels):\n",
        "    \"\"\"\n",
        "    Returns the accuracy of the model for each class\n",
        "    \"\"\"\n",
        "    predictions = map(torch.argmax, [outputs[:, i:i+n] for i, n in enumerate(n_sub_classes)])\n",
        "    true_targets = map(torch.argmax, [labels[:, i:i+n] for i, n in enumerate(n_sub_classes)])\n",
        "    return torch.tensor([torch.sum(pred == true).item() for pred, true in zip(predictions, true_targets)])\n",
        "\n",
        "def view_train_loss_vs_val_loss(train_loss, val_loss, model_name, batches_per_epoch):\n",
        "    train_batches = range(len(train_loss))\n",
        "    val_epochs = [i*batches_per_epoch for i in range(len(val_loss))]\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_batches, train_loss, label='Train loss')\n",
        "    plt.plot(val_epochs, val_loss, label='Validation loss')\n",
        "    plt.xlabel('Mini-batches')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(f'{model_name} loss after training {len(train_loss)} mini-batches')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{MEDIA_PATH}/train_vs_val_loss_{model_name}.png')\n",
        "    plt.show()\n",
        "\n",
        "def view_accuracy(val_accuracy, train_accuracy, model_name):\n",
        "    classes = range(len(val_accuracy))\n",
        "    width = 0.35\n",
        "    fig, ax = plt.subplots(figsize=(10, 5), layout='tight')\n",
        "    ax.bar([e - width/2 for e in classes], val_accuracy, width, label='Validation accuracy')\n",
        "    ax.bar([e + width/2 for e in classes], train_accuracy, width, label='Train accuracy')\n",
        "    ax.set_xlabel('Classes')\n",
        "    ax.set_xticks([i for i in range(val_accuracy.shape[0])])\n",
        "    ax.set_ylabel('Accuracy')\n",
        "    ax.set_title(f'{model_name} accuracy')\n",
        "    ax.legend()\n",
        "    plt.savefig(f'{MEDIA_PATH}/accuracy_{model_name}.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVcVrvWud191"
      },
      "source": [
        "### Results\n",
        "\n",
        "We find that all architectures utilised quickly converge during the first few epochs. Following training progress is slowed down and appears to converge at a suboptimal rate. Through a few trial attempts, we find that the initial randomization of weights does impact the performance significantly. However, distinictions between `ConvNet` and `LinNet` in terms of their predictability are hard to make as accuracy scores appear very low. This likely implies that our neural network pipeline or pre-processing of images is largely unsuccessful in capturing the detail of this dataset sufficiently.\n",
        "\n",
        "Due to the size of the transfer learning models, elaborate training analysis beyond the loss visualizations were not feasible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_RoxdmzbPO7"
      },
      "source": [
        "Parameter definition, model setup and training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609,
          "referenced_widgets": [
            "0c35fa17719d435286a873ccc1ce4c0b",
            "ff599c245efd41cd9760c1ae42f87d1f",
            "a2ce0baa8f3041a3b7533f6815a658ab",
            "486744b0f0e14acf8d26d4603087f1a1",
            "38e271f4861a481dad8cf0b12461c769",
            "ef0d1cdbcb2142628d487b206d72ab85",
            "ee6e0a04e67d44afab07a648b222caef",
            "e52ae96f0435432ebc29e4094410420e",
            "cc9cf057fb1e418e9274c374417d09be",
            "39b96be65a404e648e4c3889b89677f5",
            "b7dec6fd4eba482e98cf476cf02bb0f9",
            "1a9b186ce704494c833a3b5c0912c264",
            "6693eeed29cf4fa4ae0a1203eb50fade",
            "db1c60a9f49343f39af1232f465c19fa",
            "05c8fcfe1d924df4a444ec810db8e8c4",
            "32a5391bfebd414689d37a91e36226e9",
            "f9b9c152c1694eb9a3202e3f8340d6b7",
            "b29c3da8838b46158012b8b3f97359e2",
            "c65a3b835ead46d89382a96b786e562f",
            "f9f993c3c38b4bcbac87f3c937ce1a07",
            "ed2aa1ede0854005a77665d0dfd42f65",
            "a69d3e3fe9274d76a2b6cfb5ad1f71d5",
            "3022eed091cf430080e928402ef4f340",
            "ddfde9a6ba944b32a0ab842d0039e58e",
            "972e2affa714439584835663db3a4b02",
            "dc221f275ef24a6d90496d5f60389db7",
            "3d6a42dd55d64719a53987a6906e6d66",
            "c447a022fa2c40ab9847223edd2308a9",
            "ec8651eb35d442fc80ef5cfcebf381f2",
            "e9437285532a4c1f8e2b43a0e17c37ff",
            "652e9115fa504847ba2b04e5ebac3926",
            "4121a32da8da4feda8b97694885ceff4",
            "169120afa9bb42e497759c92fcd1fc12"
          ]
        },
        "id": "xPmD3_s0bT2L",
        "outputId": "40a1b1c5-aafd-4d1f-aec3-65228fa80437"
      },
      "outputs": [],
      "source": [
        "lr = 1e-5\n",
        "n_train_epochs = 10\n",
        "n_trial_epochs = 1\n",
        "n_trials = 10\n",
        "batch_size = 64\n",
        "dim = 64\n",
        "in_channels_preprocessed = 1\n",
        "\n",
        "criterion = rmse_loss\n",
        "\n",
        "transform_config = get_transform_config()\n",
        "train_loader = DataLoader(GalaxyDataset(train, transform_config), batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(GalaxyDataset(validation, transform_config), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "transform_config_preprocessed = get_transform_config(grayscale=True, crop=256, resize=dim)\n",
        "train_loader_preprocessed = DataLoader(GalaxyDataset(train, transform_config_preprocessed), batch_size=batch_size, shuffle=True)\n",
        "val_loader_preprocessed = DataLoader(GalaxyDataset(validation, transform_config_preprocessed), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train model configurations\n",
        "models = [\n",
        "    ConvNet(dim=dim, in_channels=in_channels_preprocessed),\n",
        "    LinNet(dim=dim, in_channels=in_channels_preprocessed),\n",
        "    DenseNet121(n_classes),\n",
        "    ResNet18(n_classes)\n",
        "    ]\n",
        "model_names = [\n",
        "    'ConvNet',\n",
        "    'LinNet',\n",
        "    'DenseNet121',\n",
        "    'ResNet18'\n",
        "    ]\n",
        "train_loaders = [\n",
        "    train_loader_preprocessed,\n",
        "    train_loader_preprocessed,\n",
        "    train_loader,\n",
        "    train_loader\n",
        "    ]\n",
        "val_loaders = [\n",
        "    val_loader_preprocessed,\n",
        "    val_loader_preprocessed,\n",
        "    val_loader,\n",
        "    val_loader\n",
        "    ]\n",
        "\n",
        "for model, model_name, train, val in zip(models, model_names, train_loaders, val_loaders):\n",
        "    optimizer = optim.Adam(model.parameters(), lr)\n",
        "    if model_name in ['ConvNet', 'LinNet']:\n",
        "        model, metrics = train_best_model(model, criterion, optimizer, lr, train, val, n_train_epochs, n_trial_epochs, n_trials, save_model=True, model_name=model_name)\n",
        "    else:\n",
        "        model, metrics = train_model(model, criterion, optimizer, train, val, n_train_epochs)\n",
        "    view_train_loss_vs_val_loss(metrics['train_loss_by_batch'], metrics['val_loss_by_epoch'], model_name, len(train))\n",
        "    val_loss, val_accuracy = validate_model(model, criterion, val)\n",
        "    train_loss, train_accuracy = validate_model(model, criterion, train)\n",
        "    view_accuracy(val_accuracy, train_accuracy, model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W080Wi_jHrHE"
      },
      "source": [
        "## Discussion\n",
        "\n",
        "There are a number of flaws in methodology and model selection that are cause for concern regarding the reliability of results. Due to the selection of large networks, training takes a large amount of time and the exploration of the parameter space in many configurations becomes infeasible. For the inital exploration, smaller models are recommended and should suffice in capturing the core of this challenge and upscaling of models be delayed unless access to appropriate hardware exists.\n",
        "\n",
        "We note that we observe the networks learn and converge to a rather suboptimal solution. This is likely due to parameterization of learning rate as well as due to the lack of further pre-processing transformations. Introduction of rotations, translations amongst others could have improved the results further, as also elaborated on by [Ethiraj et. al.](https://ieeexplore.ieee.org/abstract/document/9672430?casa_token=tzUJBHsdvfEAAAAA:KeNbqeQO8FIGaxoHdSsMf4aB_H6Jg0bUQlwwbrgMFXAk32mp7Q-1iSv_eVE7_o4Cz0xQ2u8_YZlC).\n",
        "\n",
        "The choice to not incorporate the probabilistic decision tree information was made for simplicity and according to [Ethiraj et. al.](https://ieeexplore.ieee.org/abstract/document/9672430?casa_token=tzUJBHsdvfEAAAAA:KeNbqeQO8FIGaxoHdSsMf4aB_H6Jg0bUQlwwbrgMFXAk32mp7Q-1iSv_eVE7_o4Cz0xQ2u8_YZlC) this does not majorly impact results. However, particularly in our poor performing scenario, such incorporation could have aided in improving our results.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Overall, we believe that our project has not been successful in showcasing new avenues to utilize neural networks on this dataset. However, we hope it serves as a reminder to follow a rigorous procedure starting from base principles and exploring parameter spaces at a smaller scale to enable well-designed machine learning practices target at a particular problem set.\n",
        "\n",
        "## Note on Usage of Large Language Models (LLMs)\n",
        "\n",
        "For the completion of this project, GPT-4, GPT-4o-64k and GPT-4o-128k were used through the intermediary provider [Poe](https://poe.com). Their main contributions were the generation of a draft code elements for training and validation functions as well as the creation of an outline for the report, compilation of information for the introduction and method sections, which were used as a starting reference. All content generated by the model was inspected manually and in most cases modified again before arriving at this final format."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05c8fcfe1d924df4a444ec810db8e8c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed2aa1ede0854005a77665d0dfd42f65",
            "placeholder": "​",
            "style": "IPY_MODEL_a69d3e3fe9274d76a2b6cfb5ad1f71d5",
            "value": " 1540/1540 [03:04&lt;00:00,  7.37it/s]"
          }
        },
        "0c35fa17719d435286a873ccc1ce4c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff599c245efd41cd9760c1ae42f87d1f",
              "IPY_MODEL_a2ce0baa8f3041a3b7533f6815a658ab",
              "IPY_MODEL_486744b0f0e14acf8d26d4603087f1a1"
            ],
            "layout": "IPY_MODEL_38e271f4861a481dad8cf0b12461c769"
          }
        },
        "169120afa9bb42e497759c92fcd1fc12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a9b186ce704494c833a3b5c0912c264": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6693eeed29cf4fa4ae0a1203eb50fade",
              "IPY_MODEL_db1c60a9f49343f39af1232f465c19fa",
              "IPY_MODEL_05c8fcfe1d924df4a444ec810db8e8c4"
            ],
            "layout": "IPY_MODEL_32a5391bfebd414689d37a91e36226e9"
          }
        },
        "3022eed091cf430080e928402ef4f340": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddfde9a6ba944b32a0ab842d0039e58e",
              "IPY_MODEL_972e2affa714439584835663db3a4b02",
              "IPY_MODEL_dc221f275ef24a6d90496d5f60389db7"
            ],
            "layout": "IPY_MODEL_3d6a42dd55d64719a53987a6906e6d66"
          }
        },
        "32a5391bfebd414689d37a91e36226e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "38e271f4861a481dad8cf0b12461c769": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39b96be65a404e648e4c3889b89677f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d6a42dd55d64719a53987a6906e6d66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4121a32da8da4feda8b97694885ceff4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "486744b0f0e14acf8d26d4603087f1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39b96be65a404e648e4c3889b89677f5",
            "placeholder": "​",
            "style": "IPY_MODEL_b7dec6fd4eba482e98cf476cf02bb0f9",
            "value": " 1/10 [05:41&lt;38:30, 256.74s/it]"
          }
        },
        "652e9115fa504847ba2b04e5ebac3926": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6693eeed29cf4fa4ae0a1203eb50fade": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9b9c152c1694eb9a3202e3f8340d6b7",
            "placeholder": "​",
            "style": "IPY_MODEL_b29c3da8838b46158012b8b3f97359e2",
            "value": "Loss: 0.1443: 100%"
          }
        },
        "972e2affa714439584835663db3a4b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9437285532a4c1f8e2b43a0e17c37ff",
            "max": 1540,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_652e9115fa504847ba2b04e5ebac3926",
            "value": 460
          }
        },
        "a2ce0baa8f3041a3b7533f6815a658ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e52ae96f0435432ebc29e4094410420e",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc9cf057fb1e418e9274c374417d09be",
            "value": 1
          }
        },
        "a69d3e3fe9274d76a2b6cfb5ad1f71d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b29c3da8838b46158012b8b3f97359e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7dec6fd4eba482e98cf476cf02bb0f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c447a022fa2c40ab9847223edd2308a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c65a3b835ead46d89382a96b786e562f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc9cf057fb1e418e9274c374417d09be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db1c60a9f49343f39af1232f465c19fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c65a3b835ead46d89382a96b786e562f",
            "max": 1540,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9f993c3c38b4bcbac87f3c937ce1a07",
            "value": 1540
          }
        },
        "dc221f275ef24a6d90496d5f60389db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4121a32da8da4feda8b97694885ceff4",
            "placeholder": "​",
            "style": "IPY_MODEL_169120afa9bb42e497759c92fcd1fc12",
            "value": " 460/1540 [01:24&lt;02:19,  7.73it/s]"
          }
        },
        "ddfde9a6ba944b32a0ab842d0039e58e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c447a022fa2c40ab9847223edd2308a9",
            "placeholder": "​",
            "style": "IPY_MODEL_ec8651eb35d442fc80ef5cfcebf381f2",
            "value": "Loss: 0.1608:  30%"
          }
        },
        "e52ae96f0435432ebc29e4094410420e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9437285532a4c1f8e2b43a0e17c37ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec8651eb35d442fc80ef5cfcebf381f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed2aa1ede0854005a77665d0dfd42f65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee6e0a04e67d44afab07a648b222caef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef0d1cdbcb2142628d487b206d72ab85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9b9c152c1694eb9a3202e3f8340d6b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9f993c3c38b4bcbac87f3c937ce1a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff599c245efd41cd9760c1ae42f87d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef0d1cdbcb2142628d487b206d72ab85",
            "placeholder": "​",
            "style": "IPY_MODEL_ee6e0a04e67d44afab07a648b222caef",
            "value": "Test accuracy: 0.1034238338470459:  10%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
